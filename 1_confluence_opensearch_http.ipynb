{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "812192f0-e1b8-4f71-8ee9-3f0d6637aa1a",
   "metadata": {},
   "source": [
    "# **Parse Confluence page into OCI OpenSearch Vectors**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5489b1f-f5c5-4069-9df1-55af883dc7f7",
   "metadata": {},
   "source": [
    "# **Steps**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f2e7c6-d468-4035-ac4a-45f61d91b31f",
   "metadata": {},
   "source": [
    "## **1. Load packages & change config file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936a9e89-446c-4315-b04a-b804f0968351",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install atlassian-python-api beautifulsoup4 tiktoken opensearch-py transformers torch gradio langchain langchain-huggingface\n",
    " \n",
    "from atlassian import Confluence\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import tiktoken\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from langchain.vectorstores import OpenSearchVectorSearch\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import oci\n",
    "import ads\n",
    "import os\n",
    "import json\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfadf02-37ce-4a34-bff7-5ca7fa234119",
   "metadata": {},
   "source": [
    "## **2. Change the Config.py file**\n",
    "Open the config.py and change the parameters to your Confluence and OCI OpenSearch cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2bfd13-ff9f-47ce-ac61-44b6673e6542",
   "metadata": {},
   "source": [
    "## **3. Import the custom Python functions and configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff5a427-1e71-4916-8748-b1ad0dd5c43c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from config import confluence_space_id, full_confluence_url, username_confluence, atlassian_api_token, host, username, password, index_name\n",
    "from helpers import create_confluence_client, create_opensearch_client, chunk_text, parse_page, create_embedding_model, ingest_documents_with_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370395bb-455d-4363-a27a-20f8a1ffb298",
   "metadata": {},
   "source": [
    "## **4. Define and load the embedding model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ff548d-8696-48af-8e84-8ec447a8de4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_model = create_embedding_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7329d9b-b095-4a71-b033-c935e6967b4a",
   "metadata": {},
   "source": [
    "## **5. Establish and test the connections**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf9e823-3f7c-45da-8b97-8c9ac9cd9a77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## establish connections and helpers\n",
    "confluence_client = create_confluence_client(full_confluence_url, username_confluence, atlassian_api_token)\n",
    "oci_opensearch_client = create_opensearch_client(host, username, password, index_name, embedding_model)\n",
    "\n",
    "## Test connections\n",
    "print(confluence_client.get_space(confluence_space_id))\n",
    "print(\"-\"*200)\n",
    "print(oci_opensearch_client.client.cluster.state(['cluster_name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade8d451-9468-40b8-b0d6-b81d9fdffb75",
   "metadata": {},
   "source": [
    "## **6. Create an index in OCI OpenSearch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb98fc1-d991-4b36-ac36-05f74a49f222",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "try: #delete if exists and make again\n",
    "    oci_opensearch_client.delete_index(index_name)\n",
    "    response = oci_opensearch_client.create_index(dimension = 384, index_name = index_name)\n",
    "    oci_opensearch_client.client.indices.refresh(index=index_name)\n",
    "    print(response)\n",
    "\n",
    "except (Exception, ValueError) as ex:\n",
    "    response = oci_opensearch_client.create_index(dimension = 384, index_name = index_name)\n",
    "    oci_opensearch_client.client.indices.refresh(index=index_name)\n",
    "    print(response)\n",
    "\n",
    "#oci_opensearch_client.index_exists(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802bb7b3-fb8c-4d05-bd4a-1432c6588b6c",
   "metadata": {},
   "source": [
    "## **7. Load example data, as embeddings, to the index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35057a4-fa08-45a2-98fd-a4937f1289af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_list = [\"Oracle Corporation is an American multinational computer technology company headquartered in Austin, Texas.[5] Co-founded in 1977 by Larry Ellison, who remains executive chairman, Oracle was the third-largest software company in the world in 2020 by revenue and market capitalization.[6] The company's 2023 ranking in the Forbes Global 2000 was 80.[7]\",\n",
    "                \"Larry Ellison, Bob Miner, and Ed Oates co-founded Oracle Corporation in 1977 under the name Software Development Laboratories (SDL).[2] Ellison took inspiration[9] from the 1970 paper written by Edgar F. Codd on relational database management systems (RDBMS) named A Relational Model of Data for Large Shared Data Banks.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51eca8f-0194-4cc9-8be9-2c5bcaf5e239",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load the example list, convert as embeddings and load into oci opensearch\n",
    "ingest_documents_with_embeddings(chunks=example_list, index_name=index_name, oci_opensearch_client=oci_opensearch_client, host=host, username=username, password=password, embedding_model=embedding_model, batch_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3db889-9d4b-499e-82e7-a696afd6a817",
   "metadata": {},
   "source": [
    "## **8. Check the index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee63a16-1a1e-4467-84a9-5afbb98769f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the index mapping\n",
    "response = oci_opensearch_client.client.indices.get_mapping(index=index_name)\n",
    "print(\"Index Mapping:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14fad2d-7857-4765-919f-63251dacbd02",
   "metadata": {},
   "source": [
    "## **9. Test semantic search using vector embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61ce54a-951e-4a64-8677-8ecce0efe93c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to perform a semantic search using vector embeddings\n",
    "def retrieve_documents_with_embeddings(query, top_k=5):\n",
    "    # Generate the embedding for the query using your embedding function\n",
    "    query_embedding = oci_opensearch_client.embedding_function.embed_query(query)\n",
    "    \n",
    "    # Ensure the embedding is in the correct format (e.g., a list of floats)\n",
    "    query_embedding = np.array(query_embedding).tolist()\n",
    "\n",
    "    # Perform a knn search in OpenSearch\n",
    "    search_results = oci_opensearch_client.client.search(\n",
    "        index=oci_opensearch_client.index_name,\n",
    "        body={\n",
    "            \"size\": top_k,\n",
    "            \"query\": {\n",
    "                \"knn\": {\n",
    "                    \"vector_field\": {\n",
    "                        \"vector\": query_embedding,\n",
    "                        \"k\": top_k\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    documents_with_embeddings = []\n",
    "    for hit in search_results['hits']['hits']:\n",
    "        doc_content = hit['_source']['text']\n",
    "        documents_with_embeddings.append((doc_content))\n",
    "\n",
    "    return documents_with_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc10a23-ac8a-4232-9bf4-e8fa02facb10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"What is oracle?\"\n",
    "documents_with_embeddings = retrieve_documents_with_embeddings(query,2)\n",
    "\n",
    "print(f\"Top {len(documents_with_embeddings)} documents and their embeddings for the query: \\\"{query}\\\"\")\n",
    "for idx, (content) in enumerate(documents_with_embeddings):\n",
    "    print(f\"\\nDocument {idx + 1}:\\n\")\n",
    "    print(f\"Content: {content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5004c606-e480-47bb-8dc3-24500080cf6f",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ae2e48-3d2b-44c4-a86c-1eeafa8309f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **10. Create the RAG Pipeline using LangChain, GenAI, and OCI OpenSearch as vector db**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e516b08-f6ca-4e25-a8e3-bcae52b99cb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_community.chat_models.oci_generative_ai import ChatOCIGenAI\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "\n",
    "def rag_pipeline(question, oci_opensearch_client, embedding_model):\n",
    "    \n",
    "    #Vector search on question.\n",
    "    docs = oci_opensearch_client.similarity_search_by_vector(embedding = embedding_model.embed_documents(question)[0],\n",
    "                                                         k=5)\n",
    "    docs_dict = [{\"page_content\": doc.page_content, \"metadata\": doc.metadata} for doc in docs]\n",
    "    data = \"\"\n",
    "    for doc in docs_dict:\n",
    "        data += doc['page_content'] + \"\\n\\n\"\n",
    "\n",
    "    #the llm\n",
    "    llm = ChatOCIGenAI(\n",
    "    model_id=\"cohere.command-r-16k\",\n",
    "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n",
    "    compartment_id=os.environ['NB_SESSION_COMPARTMENT_OCID'],\n",
    "    model_kwargs={\"temperature\": 0.7, \"max_tokens\": 500},\n",
    "    )\n",
    "    \n",
    "    #integration\n",
    "    prompt = PromptTemplate(\n",
    "      input_variables=[\"question\", \"data\"],\n",
    "      template=\"\"\"Using the data below, answer the question provided.\n",
    "      question: {question}\n",
    "      data: {data}\n",
    "      \"\"\",\n",
    "    )\n",
    "\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    llm_return_data = chain.run({'question': question, 'data': data})\n",
    "    \n",
    "    return llm_return_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3d9738-1247-48a4-8f89-1f3243526057",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_return_data = rag_pipeline(\"Who is Bob Peulen?\", oci_opensearch_client, embedding_model)\n",
    "llm_return_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f78bd71-a59c-4c5f-a6e0-3379a5653f13",
   "metadata": {},
   "source": [
    "## **11. Gradio - example application**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bda710-0ff0-49a3-90cb-04f93ff7557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def rag_pipeline_gradio(question, x):\n",
    "    \n",
    "    #Vector search on question.\n",
    "    docs = oci_opensearch_client.similarity_search_by_vector(embedding = embedding_model.embed_documents(question)[0],\n",
    "                                                         k=5)\n",
    "    docs_dict = [{\"page_content\": doc.page_content, \"metadata\": doc.metadata} for doc in docs]\n",
    "    data = \"\"\n",
    "    for doc in docs_dict:\n",
    "        data += doc['page_content'] + \"\\n\\n\"\n",
    "\n",
    "    #the llm\n",
    "    llm = ChatOCIGenAI(\n",
    "    model_id=\"cohere.command-r-16k\",\n",
    "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n",
    "    compartment_id=os.environ['NB_SESSION_COMPARTMENT_OCID'],\n",
    "    model_kwargs={\"temperature\": 0.7, \"max_tokens\": 500},\n",
    "    )\n",
    "    \n",
    "    #integration\n",
    "    prompt = PromptTemplate(\n",
    "      input_variables=[\"question\", \"data\"],\n",
    "      template=\"\"\"Using the data below, answer the question provided.\n",
    "      question: {question}\n",
    "      data: {data}\n",
    "      \"\"\",\n",
    "    )\n",
    "\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    llm_return_data_gradio = chain.run({'question': question, 'data': data})\n",
    "    \n",
    "    return llm_return_data_gradio\n",
    "\n",
    "\n",
    "gr.ChatInterface(\n",
    "    fn=rag_pipeline_gradio\n",
    ").launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31d6834-95cd-4b77-8d88-2a4082377be9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfb6bd7-4841-473c-a394-92f9a8179849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54718522-b89e-4bac-adab-185e88e60652",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch21_p39_gpu_v1]",
   "language": "python",
   "name": "conda-env-pytorch21_p39_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
